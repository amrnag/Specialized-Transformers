# Specialized-Transformers
This repository contains the source code for Specialized Transformers: Faster, Smaller and more Accurate NLP Models (https://openreview.net/forum?id=aUoV6qhY_e). This implementation builds on Huggingface's [Transformers](https://github.com/huggingface/transformers) library in Pytorch. Scripts from  the implementation of [BERT-of-Theseus](https://github.com/JetRunner/BERT-of-Theseus) are used to prepare files for submission to the GLUE test server.

## Dependencies
transformers 2.2.0

pytorch 1.9.1 

Tested on RTX 2080 Ti GPU with CUDA Version 11.4

## Commands

## Results
